{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 6: Analyzing Stock Sentiment from Twits\n",
    "## Instructions\n",
    "Each problem consists of a function to implement and instructions on how to implement the function.  The parts of the function that need to be implemented are marked with a `# TODO` comment.\n",
    "\n",
    "## Packages\n",
    "When you implement the functions, you'll only need to you use the packages you've used in the classroom, like [Pandas](https://pandas.pydata.org/) and [Numpy](http://www.numpy.org/). These packages will be imported for you. We recommend you don't add any import statements, otherwise the grader might not be able to run your code.\n",
    "\n",
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "When deciding the value of a company, it's important to follow the news. For example, a product recall or natural disaster in a company's product chain. You want to be able to turn this information into a signal. Currently, the best tool for the job is a Neural Network. \n",
    "\n",
    "For this project, you'll use posts from the social media site [StockTwits](https://en.wikipedia.org/wiki/StockTwits). The community on StockTwits is full of investors, traders, and entrepreneurs. Each message posted is called a Twit. This is similar to Twitter's version of a post, called a Tweet. You'll build a model around these twits that generate a sentiment score.\n",
    "\n",
    "We've collected a bunch of twits, then hand labeled the sentiment of each. To capture the degree of sentiment, we'll use a five-point scale: very negative, negative, neutral, positive, very positive. Each twit is labeled -2 to 2 in steps of 1, from very negative to very positive respectively. You'll build a sentiment analysis model that will learn to assign sentiment to twits on its own, using this labeled data.\n",
    "\n",
    "The first thing we should to do, is load the data.\n",
    "\n",
    "## Import Twits \n",
    "### Load Twits Data \n",
    "This JSON file contains a list of objects for each twit in the `'data'` field:\n",
    "\n",
    "```\n",
    "{'data':\n",
    "  {'message_body': 'Neutral twit body text here',\n",
    "   'sentiment': 0},\n",
    "  {'message_body': 'Happy twit body text here',\n",
    "   'sentiment': 1},\n",
    "   ...\n",
    "}\n",
    "```\n",
    "\n",
    "The fields represent the following:\n",
    "\n",
    "* `'message_body'`: The text of the twit.\n",
    "* `'sentiment'`: Sentiment score for the twit, ranges from -2 to 2 in steps of 1, with 0 being neutral.\n",
    "\n",
    "\n",
    "To see what the data look like by printing the first 10 twits from the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'message_body': '$FITB great buy at 26.00...ill wait', 'sentiment': 2, 'timestamp': '2018-07-01T00:00:09Z'}, {'message_body': '@StockTwits $MSFT', 'sentiment': 1, 'timestamp': '2018-07-01T00:00:42Z'}, {'message_body': '#STAAnalystAlert for $TDG : Jefferies Maintains with a rating of Hold setting target price at USD 350.00. Our own verdict is Buy  http://www.stocktargetadvisor.com/toprating', 'sentiment': 2, 'timestamp': '2018-07-01T00:01:24Z'}, {'message_body': '$AMD I heard thereâ€™s a guy who knows someone who thinks somebody knows something - on StockTwits.', 'sentiment': 1, 'timestamp': '2018-07-01T00:01:47Z'}, {'message_body': '$AMD reveal yourself!', 'sentiment': 0, 'timestamp': '2018-07-01T00:02:13Z'}, {'message_body': '$AAPL Why the drop? I warren Buffet taking out his position?', 'sentiment': 1, 'timestamp': '2018-07-01T00:03:10Z'}, {'message_body': '$BA bears have 1 reason on 06-29 to pay more attention https://dividendbot.com?s=BA', 'sentiment': -2, 'timestamp': '2018-07-01T00:04:09Z'}, {'message_body': '$BAC ok good we&#39;re not dropping in price over the weekend, lol', 'sentiment': 1, 'timestamp': '2018-07-01T00:04:17Z'}, {'message_body': '$AMAT - Daily Chart, we need to get back to above 50.', 'sentiment': 2, 'timestamp': '2018-07-01T00:08:01Z'}, {'message_body': '$GME 3% drop per week after spike... if no news in 3 months, back to 12s... if BO, then bingo... what is the odds?', 'sentiment': -2, 'timestamp': '2018-07-01T00:09:03Z'}]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('..', '..', 'data', 'project_6_stocktwits', 'twits.json'), 'r') as f:\n",
    "    twits = json.load(f)\n",
    "\n",
    "print(twits['data'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as outfile:\n",
    "    json.dump(twits, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Data\n",
    "Now let's look at the number of twits in dataset. Print the number of twits below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548010"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print out the number of twits\"\"\"\n",
    "\n",
    "# TODO Implement \n",
    "t_count = len(twits['data'])\n",
    "t_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Message Body and Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1548010, 1548010)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [twit['message_body'] for twit in twits['data']]\n",
    "# Since the sentiment scores are discrete, we'll scale the sentiments to 0 to 4 for use in our network\n",
    "sentiments = [twit['sentiment'] + 2 for twit in twits['data']]\n",
    "\n",
    "len(messages), len(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "With our data in hand we need to preprocess our text. These twits are collected by filtering on ticker symbols where these are denoted with a leader $ symbol in the twit itself. For example,\n",
    "\n",
    "`{'message_body': 'RT @google Our annual look at the year in Google blogging (and beyond) http://t.co/sptHOAh8 $GOOG',\n",
    " 'sentiment': 0}`\n",
    "\n",
    "The ticker symbols don't provide information on the sentiment, and they are in every twit, so we should remove them. This twit also has the `@google` username, again not providing sentiment information, so we should also remove it. We also see a URL `http://t.co/sptHOAh8`. Let's remove these too.\n",
    "\n",
    "The easiest way to remove specific words or phrases is with regex using the `re` module. You can sub out specific patterns with a space:\n",
    "\n",
    "```python\n",
    "re.sub(pattern, ' ', text)\n",
    "```\n",
    "This will substitute a space with anywhere the pattern matches in the text. Later when we tokenize the text, we'll split appropriately on those spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def preprocess(message):\n",
    "    \"\"\"\n",
    "    This function takes a string as input, then performs these operations: \n",
    "        - lowercase\n",
    "        - remove URLs\n",
    "        - remove ticker symbols \n",
    "        - removes punctuation\n",
    "        - tokenize by splitting the string on whitespace \n",
    "        - removes any single character tokens\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        message : The text message to be preprocessed.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        tokens: The preprocessed text into tokens.\n",
    "    \"\"\" \n",
    "    #TODO: Implement \n",
    "\n",
    "    # Lowercase the twit message\n",
    "    text = message.lower()\n",
    "    \n",
    "    # Replace URLs with a space in the message\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    \n",
    "    # Replace ticker symbols with a space. The ticker symbols are any stock symbol that starts with $.\n",
    "    text = re.sub(r\"\\$\\S+\", \" \", text)\n",
    "    \n",
    "    # Replace StockTwits usernames with a space. The usernames are any word that starts with @.\n",
    "    text = re.sub(r\"\\@\\S+\", \" \", text)\n",
    "\n",
    "    # Replace everything not a letter with a space\n",
    "    text = re.sub(r\"[^a-z]+\", \" \", text)\n",
    "    \n",
    "    # Tokenize by splitting the string on whitespace into a list of words\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "    # Lemmatize words using the WordNetLemmatizer. You can ignore any word that is not longer than one character.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [wnl.lemmatize(k, pos =\"v\") for k in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess All the Twits \n",
    "Now we can preprocess each of the twits in our dataset. Apply the function `preprocess` to all the twit messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ef4112548b45718520c9edf52c811d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1548010), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# TODO Implement\n",
    "tokenized = []\n",
    "for message in tqdm_notebook(messages):\n",
    "    tokenized.append(preprocess(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['reveal'],\n",
       " ['strong', 'buy'],\n",
       " ['short'],\n",
       " ['miss', 'days'],\n",
       " ['today', 'insight'],\n",
       " ['go', 'leave'],\n",
       " ['come'],\n",
       " ['throwback'],\n",
       " ['today', 'insight'],\n",
       " ['today', 'insight'],\n",
       " ['mad', 'still'],\n",
       " ['back', 'july'],\n",
       " ['open', 'monday'],\n",
       " ['turd']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show some short twits\n",
    "short = [k for k in tokenized if len(k) < 3]\n",
    "print(len(short))\n",
    "short[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[131968, 173130, 701597, 316447, 224868]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indicate class distribution\n",
    "i0 = [i for i, e in enumerate(sentiments) if e == 0]\n",
    "i1 = [i for i, e in enumerate(sentiments) if e == 1]\n",
    "i2 = [i for i, e in enumerate(sentiments) if e == 2]\n",
    "i3 = [i for i, e in enumerate(sentiments) if e == 3]\n",
    "i4 = [i for i, e in enumerate(sentiments) if e == 4]\n",
    "[len(i0),len(i1),len(i2),len(i3),len(i4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate twit length\n",
    "data = [len(k) for k in tokenized]\n",
    "d0 = [data[k] for k in i0]\n",
    "d1 = [data[k] for k in i1]\n",
    "d2 = [data[k] for k in i2]\n",
    "d3 = [data[k] for k in i3]\n",
    "d4 = [data[k] for k in i4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff86cea7e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "bins = np.arange(0,30, 2.5)\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15, 3), sharey=True)\n",
    "axs[0].hist(d0, bins, alpha=0.5, label='class_0')\n",
    "axs[1].hist(d1, bins, alpha=0.5, label='class_1')\n",
    "axs[2].hist(d2, bins, alpha=0.5, label='class_2')\n",
    "axs[3].hist(d3, bins, alpha=0.5, label='class_3')\n",
    "axs[4].hist(d4, bins, alpha=0.5, label='class_4')\n",
    "plt.xlim([0, 20])\n",
    "fig.suptitle('Token Count by Twit Length and Sentiment Class')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "Now with all of our messages tokenized, we want to create a vocabulary and count up how often each word appears in our entire corpus. Use the [`Counter`](https://docs.python.org/3.1/library/collections.html#collections.Counter) function to count up all the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\"\"\"\n",
    "Create a vocabulary by using Bag of words\n",
    "\"\"\"\n",
    "# TODO: Implement \n",
    "def bag_of_words(wordlists):\n",
    "    bag = Counter()\n",
    "    for words in wordlists:\n",
    "        for w in words:\n",
    "            bag[w] += 1\n",
    "    return bag\n",
    "\n",
    "bow = bag_of_words(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Words Appearing in Message\n",
    "With our vocabulary, now we'll remove some of the most common words such as 'the', 'and', 'it', etc. These words don't contribute to identifying sentiment and are really common, resulting in a lot of noise in our input. If we can filter these out, then our network should have an easier time learning.\n",
    "\n",
    "We also want to remove really rare words that show up in a only a few twits. Here you'll want to divide the count of each word by the number of messages. Then remove words that only appear in some small fraction of the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build corpus by class\n",
    "c0 = [tok for sublist in [tokenized[j] for j in i0] for tok in sublist]\n",
    "c1 = [tok for sublist in [tokenized[j] for j in i1] for tok in sublist]\n",
    "c2 = [tok for sublist in [tokenized[j] for j in i2] for tok in sublist]\n",
    "c3 = [tok for sublist in [tokenized[j] for j in i3] for tok in sublist]\n",
    "c4 = [tok for sublist in [tokenized[j] for j in i4] for tok in sublist]\n",
    "corpus =[c0,c1,c2,c3,c4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9893841"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of words\n",
    "N = len(c0)+len(c1)+len(c2)+len(c3)+len(c4)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build bags by class\n",
    "def bag_class(words):\n",
    "    bag = Counter()\n",
    "    for w in words:\n",
    "        bag[w] += 1\n",
    "    return bag\n",
    "# bags for each class\n",
    "b_c0 = bag_class(c0)\n",
    "b_c1 = bag_class(c1)\n",
    "b_c2 = bag_class(c2)\n",
    "b_c3 = bag_class(c3)\n",
    "b_c4 = bag_class(c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('short', 41783),\n",
       " ('sell', 14691),\n",
       " ('go', 12751),\n",
       " ('bear', 10275),\n",
       " ('volume', 10275),\n",
       " ('get', 7890),\n",
       " ('bearish', 6880),\n",
       " ('today', 6872),\n",
       " ('stock', 6776),\n",
       " ('red', 6570)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_c0.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('buy', 72771),\n",
       " ('go', 21829),\n",
       " ('long', 19520),\n",
       " ('strong', 13748),\n",
       " ('today', 13680),\n",
       " ('call', 13191),\n",
       " ('hold', 12702),\n",
       " ('get', 12436),\n",
       " ('back', 11779),\n",
       " ('stock', 11777)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_c4.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6279"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find common words\n",
    "# after first review recomendations, may not use this approach as set for filtering.\n",
    "s04 = set([k for k,v in b_c4.most_common(10000)]).intersection([k for k,v in b_c0.most_common(10000)])\n",
    "s13 = set([k for k,v in b_c1.most_common(10000)]).intersection([k for k,v in b_c3.most_common(10000)])\n",
    "scw = list(set([k for k,v in b_c2.most_common(10000)]).intersection(s04,s13))\n",
    "len(scw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('buy', 0.0769084179042771),\n",
       " ('report', 0.07233545002939258),\n",
       " ('go', 0.07000536172246949),\n",
       " ('short', 0.06060813560635913),\n",
       " ('q', 0.051996434131562456),\n",
       " ('stock', 0.048759374939438375),\n",
       " ('get', 0.0487535610235076),\n",
       " ('today', 0.048750331070212725),\n",
       " ('trade', 0.047076569272808316),\n",
       " ('call', 0.04655848476431031),\n",
       " ('sell', 0.04530526288589867),\n",
       " ('earn', 0.036387361838747814),\n",
       " ('market', 0.035050161174669414),\n",
       " ('estimize', 0.034084405139501686),\n",
       " ('like', 0.03405985749446063),\n",
       " ('see', 0.032773690092441264),\n",
       " ('look', 0.03224139378944581),\n",
       " ('day', 0.03135574059599098),\n",
       " ('next', 0.03034411922403602),\n",
       " ('share', 0.0301787456153384)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run once, not immutable - else recompute bow\n",
    "freqs = bow\n",
    "for k in freqs.keys():\n",
    "     freqs[k] = freqs[k] / t_count\n",
    "freqs.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119055.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest frequeny is 0.077 words/twit\n",
    "# number of times highest frequency word 'buy' occurs\n",
    "freqs['buy']*t_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20938"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the following variables:\n",
    "    freqs\n",
    "    low_cutoff\n",
    "    high_cutoff\n",
    "    K_most_common\n",
    "\"\"\"\n",
    "\n",
    "# TODO Implement \n",
    "\n",
    "# Dictionary that contains the Frequency of words appearing in messages.\n",
    "# The key is the token and the value is the frequency of that word in the corpus.\n",
    "# Reviewer recommends this function.\n",
    "freqs = freqs\n",
    "\n",
    "# Float that is the frequency cutoff. Drop words with a frequency that is lower or equal to this number.\n",
    "# Reviewer recommends 0.0000002 to 0.000007\n",
    "low_cutoff = 0.000004\n",
    "\n",
    "# Integer that is the cut off for most common words. Drop words that are the `high_cutoff` most common words.\n",
    "# Reviewer recommends high frequency cut off from 5 to 20.\n",
    "# This means no words are cut off at the high frequency end.\n",
    "high_cutoff = 5\n",
    "\n",
    "# The k most common words in the corpus. Use `high_cutoff` as the k.\n",
    "K_most_common = [word for word in freqs if (freqs[word] > high_cutoff)]\n",
    "\n",
    "filtered_words = [word for word in freqs if (freqs[word] > low_cutoff and word not in K_most_common)]\n",
    "# expect empty list\n",
    "print(K_most_common)\n",
    "len(filtered_words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Vocabulary by Removing Filtered Words\n",
    "Let's creat three variables that will help with our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set the following variables:\n",
    "    vocab\n",
    "    id2vocab\n",
    "    filtered\n",
    "\"\"\"\n",
    "#TODO Implement\n",
    "\n",
    "# A dictionary for the `filtered_words`. The key is the word and value is an id that represents the word. \n",
    "# Reviewer recommended improvement to start at 1\n",
    "vocab = {word:i for i, word in enumerate(filtered_words,1)}\n",
    "\n",
    "# Reverse of the `vocab` dictionary. The key is word id and value is the word. \n",
    "id2vocab = {v:k for v,k in enumerate(filtered_words)}\n",
    "\n",
    "# tokenized with the words not in `filtered_words` removed.\n",
    "filtered = []\n",
    "for wlist in tokenized:\n",
    "    flist =[]\n",
    "    for w in wlist:\n",
    "        if w in vocab:\n",
    "            flist.append(w)\n",
    "    filtered.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20938"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1548010, 1548010)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered), len(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a pickle file to streamline inference later!\n",
    "with open('vocab_r1.pickle', 'wb') as handle:\n",
    "    pickle.dump(vocab, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the classes\n",
    "Let's do a few last pre-processing steps. If we look at how our twits are labeled, we'll find that 50% of them are neutral. This means that our network will be 50% accurate just by guessing 0 every single time. To help our network learn appropriately, we'll want to balance our classes.\n",
    "That is, make sure each of our different sentiment scores show up roughly as frequently in the data.\n",
    "\n",
    "What we can do here is go through each of our examples and randomly drop twits with neutral sentiment. What should be the probability we drop these twits if we want to get around 20% neutral twits starting at 50% neutral? We should also take this opportunity to remove messages with length 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[130124, 170158, 662211, 305373, 221899]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find indices of filter messages with length greater than 0\n",
    "i0f = [i for i in i0 if len(filtered[i]) > 0]\n",
    "i1f = [i for i in i1 if len(filtered[i]) > 0]\n",
    "i2f = [i for i in i2 if len(filtered[i]) > 0]\n",
    "i3f = [i for i in i3 if len(filtered[i]) > 0]\n",
    "i4f = [i for i in i4 if len(filtered[i]) > 0]\n",
    "# print out how many of each class are available\n",
    "[len(i0f),len(i1f),len(i2f),len(i3f),len(i4f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random shuffle the index lists\n",
    "random.seed(13)\n",
    "random.shuffle(i0f)\n",
    "random.shuffle(i1f)\n",
    "random.shuffle(i2f)\n",
    "random.shuffle(i3f)\n",
    "random.shuffle(i4f)\n",
    "\n",
    "# sample for stratified classes\n",
    "# split into 10 mini-batches for training later\n",
    "ind_filt = []\n",
    "for i in range(10):\n",
    "    near, far = i*13000, i*13000+13000\n",
    "    mini_list = i0f[near:far]+i1f[near:far]+i2f[near:far]+i3f[near:far]+i4f[near:far]                             \n",
    "    random.shuffle(mini_list) \n",
    "    ind_filt.append(mini_list)                        \n",
    "\n",
    "# print number of twits in data to use\n",
    "sum([len(i) for i in ind_filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind_filt[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1548010, 1548010)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiments), len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[637790, 1150029, 131768, 699598, 603329, 173082, 484786, 1213321, 173326, 529399]\n"
     ]
    }
   ],
   "source": [
    "print(ind_filt[9][10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mini batch of balanced dictionaries\n",
    "minibal = []\n",
    "for j in range(10):\n",
    "    mini = ind_filt[j]\n",
    "    m_list = []\n",
    "    s_list = []\n",
    "    for inum in mini:\n",
    "        m_list.append(filtered[inum])\n",
    "        s_list.append(sentiments[inum])\n",
    "    balm = {'messages': m_list, 'sentiments':s_list}   \n",
    "    minibal.append(balm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did it correctly, you should see the following result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# assess percentage for every mini-batch\n",
    "for i in range(10):\n",
    "    n_neutral = sum(1 for each in minibal[i]['sentiments'] if each == 2)\n",
    "    N_examples = len(minibal[i]['sentiments'])\n",
    "    print(n_neutral/N_examples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's convert our tokens into integer ids which we can pass to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lists for mini-batching\n",
    "tid_list = []\n",
    "sen_list = []\n",
    "for i in range(10):\n",
    "    tid_list.append([[vocab[word] for word in message] for message in minibal[i]['messages']])\n",
    "    sen_list.append(minibal[i]['sentiments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 4, 2, 2, 1, 4, 3, 0, 1, 2, 2, 3, 1, 0, 1, 4, 0, 2, 0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_list[8][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stanley', 'hat', 'three', 'profit']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2vocab[k] for k in tid_list[8][777]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Now we have our vocabulary which means we can transform our tokens into ids, which are then passed to our network. So, let's define the network now!\n",
    "\n",
    "Here is a nice diagram showing the network we'd like to build: \n",
    "\n",
    "#### Embed -> RNN -> Dense -> Softmax\n",
    "### Implement the text classifier\n",
    "Before we build text classifier, if you remember from the other network that you built in  \"Sentiment Analysis with an RNN\"  exercise  - which there, the network called \" SentimentRNN\", here we named it \"TextClassifer\" - consists of three main parts: 1) init function `__init__` 2) forward pass `forward`  3) hidden state `init_hidden`. \n",
    "\n",
    "This network is pretty similar to the network you built expect in the  `forward` pass, we use softmax instead of sigmoid. The reason we are not using sigmoid is that the output of NN is not a binary. In our network, sentiment scores have 5 possible outcomes. We are looking for an outcome with the highest probability thus softmax is a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, lstm_size, output_size, lstm_layers=2, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        Parameters\n",
    "        ----------\n",
    "            vocab_size : The vocabulary size.\n",
    "            embed_size : The embedding layer size.\n",
    "            lstm_size : The LSTM layer size.\n",
    "            output_size : The output size.\n",
    "            lstm_layers : The number of LSTM layers.\n",
    "            dropout : The dropout probability.\n",
    "        \"\"\"\n",
    "    \n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # TODO Implement\n",
    "        \n",
    "        # Setup embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        # Setup LSTM layer\n",
    "        # Reviewer advises batch_first=False as input is tuple of (seq_len,batch_size)\n",
    "        self.lstm = nn.LSTM(embed_size, lstm_size, lstm_layers, dropout = dropout, batch_first=False)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear layer\n",
    "        self.fc = nn.Linear(lstm_size, output_size)\n",
    "        \n",
    "        # sigmoid layer\n",
    "        self.sig = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\" \n",
    "        Initializes hidden state\n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size : The size of batches.\n",
    "        Returns\n",
    "        -------\n",
    "            hidden_state   \n",
    "        \"\"\"\n",
    "        # Initialize in CPU, then move to GPU for training\n",
    "            \n",
    "        # TODO Implement \n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_().cuda(),\n",
    "                  weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_(),\n",
    "                      weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_())\n",
    "            \n",
    "        # Reviewer recommends following function to switch CPU to GPU for  training    \n",
    "        for each in hidden:\n",
    "            each.to(device)    \n",
    "        \n",
    "        return hidden\n",
    "\n",
    "\n",
    "    def forward(self, nn_input, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on nn_input.\n",
    "        Parameters\n",
    "        ----------\n",
    "            nn_input : The batch of input to the NN.\n",
    "            hidden_state : The LSTM hidden state.\n",
    "        Returns\n",
    "        -------\n",
    "            logps: log softmax output\n",
    "            hidden_state: The new hidden state.\n",
    "        \"\"\"\n",
    "        # TODO Implement \n",
    "        batch_size = nn_input.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        #nn_input = nn_input.long()\n",
    "        embeds = self.embedding(nn_input)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        #lstm_out = lstm_out.contiguous().view(-1, self.lstm_size)\n",
    "        # we are using a softmax layer we simplify implementation\n",
    "        # reviewer recommends following format\n",
    "        lstm_out = lstm_out[-1,:,:]\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # log sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        # reviewer recommends removing\n",
    "        # sig_out = sig_out.view(batch_size, -1)\n",
    "        # sig_out = sig_out[:,-5:] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassifier(\n",
      "  (embedding): Embedding(20939, 400)\n",
      "  (lstm): LSTM(400, 256, dropout=0.2)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (sig): LogSoftmax()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab)+1  # +1 for the 0 padding + our word tokens\n",
    "embed_size = 400\n",
    "lstm_size = 256\n",
    "output_size = 5\n",
    "lstm_layers = 1\n",
    "dropout = 0.2\n",
    "\n",
    "model = TextClassifier(vocab_size, embed_size, lstm_size, output_size, lstm_layers, dropout)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 20])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randint(0, 19000, (40, 20), dtype=torch.int64)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1856,  0.1857,  0.2164,  0.2161,  0.1962],\n",
      "        [ 0.2064,  0.1956,  0.1725,  0.1903,  0.2351],\n",
      "        [ 0.1862,  0.1953,  0.1875,  0.2319,  0.1992],\n",
      "        [ 0.1985,  0.2008,  0.1691,  0.2011,  0.2305],\n",
      "        [ 0.1819,  0.2334,  0.2041,  0.2101,  0.1705],\n",
      "        [ 0.1591,  0.1688,  0.2325,  0.2642,  0.1753],\n",
      "        [ 0.2151,  0.2048,  0.1993,  0.2073,  0.1735],\n",
      "        [ 0.1966,  0.1922,  0.1765,  0.2488,  0.1858],\n",
      "        [ 0.2137,  0.1869,  0.2244,  0.2083,  0.1667],\n",
      "        [ 0.2129,  0.1697,  0.1853,  0.1991,  0.2330],\n",
      "        [ 0.2274,  0.1987,  0.1963,  0.2035,  0.1741],\n",
      "        [ 0.2125,  0.1887,  0.2005,  0.2078,  0.1904],\n",
      "        [ 0.2117,  0.1907,  0.1765,  0.1965,  0.2245],\n",
      "        [ 0.1748,  0.1860,  0.2184,  0.2200,  0.2008],\n",
      "        [ 0.2323,  0.2172,  0.1914,  0.1595,  0.1996],\n",
      "        [ 0.1986,  0.1994,  0.2036,  0.1901,  0.2083],\n",
      "        [ 0.2253,  0.2034,  0.1680,  0.2059,  0.1973],\n",
      "        [ 0.1866,  0.2323,  0.1754,  0.1966,  0.2091],\n",
      "        [ 0.2184,  0.2145,  0.1968,  0.1754,  0.1949],\n",
      "        [ 0.2053,  0.1903,  0.2173,  0.2011,  0.1861]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Try a sample\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input = torch.randint(0, 19000, (40, 20), dtype=torch.int64)\n",
    "\n",
    "if(train_on_gpu):\n",
    "    input = input.to('cuda')\n",
    "    model = model.to('cuda')\n",
    "\n",
    "hidden = model.init_hidden(20)\n",
    "\n",
    "logps, _ = model.forward(input, hidden)\n",
    "print(torch.exp(logps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### DataLoaders and Batching\n",
    "Now we should build a generator that we can use to loop through our data. It'll be more efficient if we can pass our sequences in as batches. Our input tensors should look like `(sequence_length, batch_size)`. So if our sequences are 40 tokens long and we pass in 25 sequences, then we'd have an input size of `(40, 25)`.\n",
    "\n",
    "If we set our sequence length to 40, what do we do with messages that are more or less than 40 tokens? For messages with fewer than 40 tokens, we will pad the empty spots with zeros. We should be sure to **left** pad so that the RNN starts from nothing before going through the data. If the message has 20 tokens, then the first 20 spots of our 40 long sequence will be 0. If a message has more than 40 tokens, we'll just keep the first 40 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(token_ids, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    if len(token_ids)>40:\n",
    "        tid = token_ids[:40]\n",
    "    else:\n",
    "        tid = token_ids\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    zeros = [0] * (seq_length - len(tid))\n",
    "\n",
    "    # for each twit int, I grab that review and \n",
    "    features = zeros + tid\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of lists\n",
    "def pad_list(t_list, seq_len):\n",
    "    t0 = []\n",
    "    for i in t_list:\n",
    "        ti = pad_features(i,seq_len)\n",
    "        t0.append(ti)\n",
    "    return np.asarray(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features and labels - minibatch\n",
    "feat_list = []\n",
    "lab_list = []\n",
    "for i in range(10):\n",
    "    features = pad_list(tid_list[i], 40)\n",
    "    labels = np.asarray(sen_list[i])\n",
    "    feat_list.append(features)\n",
    "    lab_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65000, 40), (65000,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the shapes\n",
    "feat_list[3].shape, lab_list[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and  Validation\n",
    "With our data in nice shape, we'll split it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(52000, 40) \n",
      "Valid set: \t\t(13000, 40)\n"
     ]
    }
   ],
   "source": [
    "# define test train verification splits\n",
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "# loop for mini-batches\n",
    "tx_list = []\n",
    "vx_list = []\n",
    "ty_list = []\n",
    "vy_list = []\n",
    "for i in range(10):\n",
    "    split_idx = int(len(tid_list[i])*split_frac)\n",
    "    train_x, remaining_x = feat_list[i][:split_idx], feat_list[i][split_idx:]\n",
    "    train_y, remaining_y = lab_list[i][:split_idx], lab_list[i][split_idx:]\n",
    "\n",
    "    valid_idx = int(len(remaining_x))\n",
    "    valid_x = remaining_x[:valid_idx]\n",
    "    valid_y = remaining_y[:valid_idx]\n",
    "    \n",
    "    tx_list.append(train_x)\n",
    "    vx_list.append(valid_x)\n",
    "    ty_list.append(train_y)\n",
    "    vy_list.append(valid_y)\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(tx_list[3].shape), \n",
    "      \"\\nValid set: \\t\\t{}\".format(vx_list[3].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini batch format data for dataloaders\n",
    "def format_data(minibatch):\n",
    "    i = minibatch\n",
    "    if(train_on_gpu):\n",
    "        train_data = TensorDataset(torch.from_numpy(tx_list[i]), torch.from_numpy(ty_list[i]).type(torch.cuda.LongTensor))\n",
    "        valid_data = TensorDataset(torch.from_numpy(vx_list[i]), torch.from_numpy(vy_list[i]).type(torch.cuda.LongTensor))\n",
    "    else:\n",
    "        train_data = TensorDataset(torch.from_numpy(tx_list[i]), torch.from_numpy(ty_list[i]).type(torch.LongTensor))\n",
    "        valid_data = TensorDataset(torch.from_numpy(vx_list[i]), torch.from_numpy(vy_list[i]).type(torch.LongTensor))\n",
    "    \n",
    "    return train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([20, 40])\n",
      "Sample input: \n",
      " tensor([[     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,    128,\n",
      "           3554,   3555,    145,   4841,   1775,    802,   1292,   1481],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,     19,   1351,    606],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,   1063,   1064,    482,     41,   2473],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,  11475,    870],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,    980,    980,    413,   1017],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,   3300,   3301,   3302],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "           1425,     87,    589,    127,   1426,      2,    774,     87],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,    309,    165,    629,  12675],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,   1526,    970],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,     40,    213,   2165],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,    165],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,    606,   6861,    334,     61,    241,    242,     12],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,   4966,    699,    171,    548,     11,    158,     29,\n",
      "           3370,    175,   1020,    146,    308,   3158,   3437,    301],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,   3758,      2],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,    591,   5382,    546,      2,    572,   8749,\n",
      "          12139,   1228,   1518,  15054,   1187,    216,   7039,   3034],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,   1029,     88,\n",
      "            802,   1895,     41,    118,   2064,    110,    303,   1094],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,     88,   2677,    177],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,    676],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            524,   8988,   8274,     71,   4155,   1488,      2,    180],\n",
      "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,     40,     40,     34]])\n",
      "\n",
      "Sample label size:  torch.Size([20])\n",
      "Sample label: \n",
      " tensor([ 1,  3,  4,  4,  3,  3,  2,  1,  2,  2,  1,  3,  0,  4,\n",
      "         4,  0,  0,  1,  1,  3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "train_data, valid_data = format_data(0)\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 20\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 40])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch, labels = sample_x, sample_y\n",
    "\n",
    "if(train_on_gpu):\n",
    "    text_batch = text_batch.to('cuda')\n",
    "    labels = labels.to('cuda')\n",
    "    model = model.to('cuda')\n",
    "    \n",
    "hidden = model.init_hidden(20)\n",
    "\n",
    "logps, hidden = model.forward(text_batch.t(), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 40])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.7629, -1.7693, -1.5947, -1.4647, -1.4966],\n",
       "         [-1.5881, -1.5744, -1.5787, -1.6781, -1.6317],\n",
       "         [-1.5937, -1.6758, -1.6284, -1.4373, -1.7381],\n",
       "         [-1.6817, -1.5723, -1.4936, -1.6779, -1.6345],\n",
       "         [-1.5014, -1.6649, -1.6025, -1.5573, -1.7379],\n",
       "         [-1.6962, -1.6428, -1.4976, -1.6392, -1.5828],\n",
       "         [-1.5441, -1.6341, -1.4302, -1.7180, -1.7563],\n",
       "         [-1.6659, -1.6834, -1.6304, -1.5700, -1.5080],\n",
       "         [-1.5524, -1.4527, -1.7170, -1.6179, -1.7350],\n",
       "         [-1.6219, -1.7040, -1.5524, -1.4416, -1.7589],\n",
       "         [-1.5719, -1.8089, -1.6179, -1.4974, -1.5775],\n",
       "         [-1.6166, -1.8542, -1.5523, -1.5768, -1.4852],\n",
       "         [-1.5081, -1.6735, -1.5859, -1.6456, -1.6428],\n",
       "         [-1.6582, -1.6934, -1.6908, -1.3544, -1.6975],\n",
       "         [-1.4854, -1.6675, -1.6303, -1.5720, -1.7072],\n",
       "         [-1.5100, -1.6382, -1.6169, -1.6317, -1.6573],\n",
       "         [-1.6925, -1.5207, -1.7854, -1.5108, -1.5658],\n",
       "         [-1.5971, -1.5882, -1.8595, -1.5909, -1.4535],\n",
       "         [-1.5647, -1.6667, -1.6112, -1.5097, -1.7073],\n",
       "         [-1.5347, -1.6417, -1.4525, -1.6458, -1.8079]], device='cuda:0'),\n",
       " tensor([ 1,  3,  4,  4,  3,  3,  2,  1,  2,  2,  1,  3,  0,  4,\n",
       "          4,  0,  0,  1,  1,  3], device='cuda:0'))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logps, sample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32.8013, device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss(size_average=False)\n",
    "\n",
    "criterion(logps, sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "It's time to train the neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (embedding): Embedding(20939, 400)\n",
       "  (lstm): LSTM(400, 256, num_layers=2, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (sig): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TextClassifier(len(vocab)+1, 400, 256, 5, lstm_layers=2, dropout=0.2)\n",
    "model.embedding.weight.data.uniform_(-1, 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resume_weights_mb1.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-ea68bd986bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"resume_weights_mb{}.pth\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resume_weights_mb1.pth'"
     ]
    }
   ],
   "source": [
    "# Load Model to Resume Training after Notebook Timeout Reset, Connection Lost, etc.\n",
    "# cuda = torch.cuda.is_available()\n",
    "# edit last minibatch number\n",
    "\n",
    "minibatch = 1\n",
    "\n",
    "PATH = \"resume_weights_mb{}.pth\".format(minibatch)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "\n",
    "if cuda:\n",
    "    checkpoint = torch.load(resume_weights)\n",
    "else:\n",
    "    # Load GPU model on CPU\n",
    "    checkpoint = torch.load(resume_weights,\n",
    "                            map_location=lambda storage,\n",
    "                            loc: storage)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "print(\"=> loaded checkpoint '{}' (trained for {} epochs)\".format(resume_weights, checkpoint['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Epoch: 1/3... Minibatch: 0... Step: 500... Loss: 31.869043... Val Loss: 28.114488\n",
      "Epoch: 1/3... Minibatch: 0... Step: 1000... Loss: 27.007980... Val Loss: 25.770126\n",
      "Epoch: 1/3... Minibatch: 0... Step: 1500... Loss: 20.666315... Val Loss: 24.282669\n",
      "Epoch: 1/3... Minibatch: 0... Step: 2000... Loss: 22.688698... Val Loss: 23.616689\n",
      "Epoch: 1/3... Minibatch: 0... Step: 2500... Loss: 29.969746... Val Loss: 23.169411\n",
      "Epoch: 1/3... Minibatch: 1... Step: 500... Loss: 17.887547... Val Loss: 22.046029\n",
      "Epoch: 1/3... Minibatch: 1... Step: 1000... Loss: 25.570969... Val Loss: 21.656672\n",
      "Epoch: 1/3... Minibatch: 1... Step: 1500... Loss: 26.875380... Val Loss: 21.297452\n",
      "Epoch: 1/3... Minibatch: 1... Step: 2000... Loss: 18.843317... Val Loss: 21.083116\n",
      "Epoch: 1/3... Minibatch: 1... Step: 2500... Loss: 19.870188... Val Loss: 20.822451\n",
      "Epoch: 1/3... Minibatch: 2... Step: 500... Loss: 21.482084... Val Loss: 20.872226\n",
      "Epoch: 1/3... Minibatch: 2... Step: 1000... Loss: 21.719761... Val Loss: 20.680007\n",
      "Epoch: 1/3... Minibatch: 2... Step: 1500... Loss: 18.148344... Val Loss: 20.385032\n",
      "Epoch: 1/3... Minibatch: 2... Step: 2000... Loss: 15.846861... Val Loss: 20.347523\n",
      "Epoch: 1/3... Minibatch: 2... Step: 2500... Loss: 21.636848... Val Loss: 20.042413\n",
      "Epoch: 1/3... Minibatch: 3... Step: 500... Loss: 22.687206... Val Loss: 20.066067\n",
      "Epoch: 1/3... Minibatch: 3... Step: 1000... Loss: 18.099735... Val Loss: 20.006238\n",
      "Epoch: 1/3... Minibatch: 3... Step: 1500... Loss: 19.692753... Val Loss: 19.806617\n",
      "Epoch: 1/3... Minibatch: 3... Step: 2000... Loss: 17.078960... Val Loss: 19.829608\n",
      "Epoch: 1/3... Minibatch: 3... Step: 2500... Loss: 17.323235... Val Loss: 19.815373\n",
      "Epoch: 1/3... Minibatch: 4... Step: 500... Loss: 19.296381... Val Loss: 19.273136\n",
      "Epoch: 1/3... Minibatch: 4... Step: 1000... Loss: 15.833774... Val Loss: 19.095749\n",
      "Epoch: 1/3... Minibatch: 4... Step: 1500... Loss: 22.901510... Val Loss: 19.100646\n",
      "Epoch: 1/3... Minibatch: 4... Step: 2000... Loss: 21.878885... Val Loss: 18.913412\n",
      "Epoch: 1/3... Minibatch: 4... Step: 2500... Loss: 18.574230... Val Loss: 18.890189\n",
      "Epoch: 1/3... Minibatch: 5... Step: 500... Loss: 25.161106... Val Loss: 18.549664\n",
      "Epoch: 1/3... Minibatch: 5... Step: 1000... Loss: 16.286404... Val Loss: 18.490024\n",
      "Epoch: 1/3... Minibatch: 5... Step: 1500... Loss: 24.329365... Val Loss: 18.467217\n",
      "Epoch: 1/3... Minibatch: 5... Step: 2000... Loss: 23.124340... Val Loss: 18.343542\n",
      "Epoch: 1/3... Minibatch: 5... Step: 2500... Loss: 21.180344... Val Loss: 18.315422\n",
      "Epoch: 1/3... Minibatch: 6... Step: 500... Loss: 23.440088... Val Loss: 18.520075\n",
      "Epoch: 1/3... Minibatch: 6... Step: 1000... Loss: 20.612688... Val Loss: 18.447605\n",
      "Epoch: 1/3... Minibatch: 6... Step: 1500... Loss: 29.390326... Val Loss: 18.496811\n",
      "Epoch: 1/3... Minibatch: 6... Step: 2000... Loss: 15.350045... Val Loss: 18.395660\n",
      "Epoch: 1/3... Minibatch: 6... Step: 2500... Loss: 14.271852... Val Loss: 18.334272\n",
      "Epoch: 1/3... Minibatch: 7... Step: 500... Loss: 12.458618... Val Loss: 18.268891\n",
      "Epoch: 1/3... Minibatch: 7... Step: 1000... Loss: 15.812107... Val Loss: 18.138154\n",
      "Epoch: 1/3... Minibatch: 7... Step: 1500... Loss: 17.877880... Val Loss: 18.063344\n",
      "Epoch: 1/3... Minibatch: 7... Step: 2000... Loss: 17.553696... Val Loss: 18.066305\n",
      "Epoch: 1/3... Minibatch: 7... Step: 2500... Loss: 19.438231... Val Loss: 18.108735\n",
      "Epoch: 1/3... Minibatch: 8... Step: 500... Loss: 10.528555... Val Loss: 18.017031\n",
      "Epoch: 1/3... Minibatch: 8... Step: 1000... Loss: 15.616902... Val Loss: 17.998200\n",
      "Epoch: 1/3... Minibatch: 8... Step: 1500... Loss: 21.736984... Val Loss: 18.040372\n",
      "Epoch: 1/3... Minibatch: 8... Step: 2000... Loss: 17.472244... Val Loss: 17.908133\n",
      "Epoch: 1/3... Minibatch: 8... Step: 2500... Loss: 14.357338... Val Loss: 17.899707\n",
      "Epoch: 1/3... Minibatch: 9... Step: 500... Loss: 15.858075... Val Loss: 17.963933\n",
      "Epoch: 1/3... Minibatch: 9... Step: 1000... Loss: 19.574461... Val Loss: 17.834094\n",
      "Epoch: 1/3... Minibatch: 9... Step: 1500... Loss: 17.961432... Val Loss: 17.824607\n",
      "Epoch: 1/3... Minibatch: 9... Step: 2000... Loss: 11.583477... Val Loss: 17.851116\n",
      "Epoch: 1/3... Minibatch: 9... Step: 2500... Loss: 21.691662... Val Loss: 17.819094\n",
      "Starting epoch 2\n",
      "Epoch: 2/3... Minibatch: 0... Step: 500... Loss: 17.108942... Val Loss: 17.847481\n",
      "Epoch: 2/3... Minibatch: 0... Step: 1000... Loss: 16.148636... Val Loss: 17.800748\n",
      "Epoch: 2/3... Minibatch: 0... Step: 1500... Loss: 21.093309... Val Loss: 17.872030\n",
      "Epoch: 2/3... Minibatch: 0... Step: 2000... Loss: 21.470917... Val Loss: 17.879145\n",
      "Epoch: 2/3... Minibatch: 0... Step: 2500... Loss: 22.351791... Val Loss: 17.785183\n",
      "Epoch: 2/3... Minibatch: 1... Step: 500... Loss: 19.219666... Val Loss: 17.699625\n",
      "Epoch: 2/3... Minibatch: 1... Step: 1000... Loss: 17.449894... Val Loss: 17.657418\n",
      "Epoch: 2/3... Minibatch: 1... Step: 1500... Loss: 15.363989... Val Loss: 17.533222\n",
      "Epoch: 2/3... Minibatch: 1... Step: 2000... Loss: 15.340067... Val Loss: 17.603636\n",
      "Epoch: 2/3... Minibatch: 1... Step: 2500... Loss: 10.541773... Val Loss: 17.516639\n",
      "Epoch: 2/3... Minibatch: 2... Step: 500... Loss: 12.751537... Val Loss: 17.717255\n",
      "Epoch: 2/3... Minibatch: 2... Step: 1000... Loss: 11.629381... Val Loss: 17.708131\n",
      "Epoch: 2/3... Minibatch: 2... Step: 1500... Loss: 18.016422... Val Loss: 17.646832\n",
      "Epoch: 2/3... Minibatch: 2... Step: 2000... Loss: 12.705705... Val Loss: 17.650820\n",
      "Epoch: 2/3... Minibatch: 2... Step: 2500... Loss: 14.226244... Val Loss: 17.675410\n",
      "Epoch: 2/3... Minibatch: 3... Step: 500... Loss: 14.327896... Val Loss: 17.761155\n",
      "Epoch: 2/3... Minibatch: 3... Step: 1000... Loss: 18.637238... Val Loss: 17.783856\n",
      "Epoch: 2/3... Minibatch: 3... Step: 1500... Loss: 15.841126... Val Loss: 17.804640\n",
      "Epoch: 2/3... Minibatch: 3... Step: 2000... Loss: 17.268642... Val Loss: 17.774751\n",
      "Epoch: 2/3... Minibatch: 3... Step: 2500... Loss: 8.748877... Val Loss: 17.802424\n",
      "Epoch: 2/3... Minibatch: 4... Step: 500... Loss: 15.800731... Val Loss: 17.358684\n",
      "Epoch: 2/3... Minibatch: 4... Step: 1000... Loss: 17.205986... Val Loss: 17.421946\n",
      "Epoch: 2/3... Minibatch: 4... Step: 1500... Loss: 15.748997... Val Loss: 17.350031\n",
      "Epoch: 2/3... Minibatch: 4... Step: 2000... Loss: 18.342871... Val Loss: 17.303972\n",
      "Epoch: 2/3... Minibatch: 4... Step: 2500... Loss: 24.341406... Val Loss: 17.353524\n",
      "Epoch: 2/3... Minibatch: 5... Step: 500... Loss: 14.963093... Val Loss: 17.054217\n",
      "Epoch: 2/3... Minibatch: 5... Step: 1000... Loss: 15.548436... Val Loss: 17.114914\n",
      "Epoch: 2/3... Minibatch: 5... Step: 1500... Loss: 18.998596... Val Loss: 17.036273\n",
      "Epoch: 2/3... Minibatch: 5... Step: 2000... Loss: 19.059841... Val Loss: 17.151591\n",
      "Epoch: 2/3... Minibatch: 5... Step: 2500... Loss: 14.202049... Val Loss: 17.078186\n",
      "Epoch: 2/3... Minibatch: 6... Step: 500... Loss: 14.106483... Val Loss: 17.456569\n",
      "Epoch: 2/3... Minibatch: 6... Step: 1000... Loss: 7.220949... Val Loss: 17.407465\n",
      "Epoch: 2/3... Minibatch: 6... Step: 1500... Loss: 14.386266... Val Loss: 17.352364\n",
      "Epoch: 2/3... Minibatch: 6... Step: 2000... Loss: 19.704556... Val Loss: 17.287883\n",
      "Epoch: 2/3... Minibatch: 6... Step: 2500... Loss: 15.685429... Val Loss: 17.250415\n",
      "Epoch: 2/3... Minibatch: 7... Step: 500... Loss: 14.858457... Val Loss: 17.184857\n",
      "Epoch: 2/3... Minibatch: 7... Step: 1000... Loss: 16.812113... Val Loss: 17.195824\n",
      "Epoch: 2/3... Minibatch: 7... Step: 1500... Loss: 14.092868... Val Loss: 17.107971\n",
      "Epoch: 2/3... Minibatch: 7... Step: 2000... Loss: 17.501785... Val Loss: 17.189394\n",
      "Epoch: 2/3... Minibatch: 7... Step: 2500... Loss: 18.011589... Val Loss: 17.114554\n",
      "Epoch: 2/3... Minibatch: 8... Step: 500... Loss: 12.397402... Val Loss: 17.227603\n",
      "Epoch: 2/3... Minibatch: 8... Step: 1000... Loss: 14.235359... Val Loss: 17.175528\n",
      "Epoch: 2/3... Minibatch: 8... Step: 1500... Loss: 15.343373... Val Loss: 17.194519\n",
      "Epoch: 2/3... Minibatch: 8... Step: 2000... Loss: 17.398851... Val Loss: 17.136472\n",
      "Epoch: 2/3... Minibatch: 8... Step: 2500... Loss: 13.526597... Val Loss: 17.223036\n",
      "Epoch: 2/3... Minibatch: 9... Step: 500... Loss: 19.842762... Val Loss: 17.132997\n",
      "Epoch: 2/3... Minibatch: 9... Step: 1000... Loss: 13.056770... Val Loss: 17.256658\n",
      "Epoch: 2/3... Minibatch: 9... Step: 1500... Loss: 10.308987... Val Loss: 17.187416\n",
      "Epoch: 2/3... Minibatch: 9... Step: 2000... Loss: 16.319103... Val Loss: 17.173836\n",
      "Epoch: 2/3... Minibatch: 9... Step: 2500... Loss: 15.807605... Val Loss: 17.146730\n",
      "Starting epoch 3\n",
      "Epoch: 3/3... Minibatch: 0... Step: 500... Loss: 11.350356... Val Loss: 17.235153\n",
      "Epoch: 3/3... Minibatch: 0... Step: 1000... Loss: 16.329155... Val Loss: 17.173598\n",
      "Epoch: 3/3... Minibatch: 0... Step: 1500... Loss: 21.285315... Val Loss: 17.186186\n",
      "Epoch: 3/3... Minibatch: 0... Step: 2000... Loss: 14.625992... Val Loss: 17.205152\n",
      "Epoch: 3/3... Minibatch: 0... Step: 2500... Loss: 10.027359... Val Loss: 17.147371\n",
      "Epoch: 3/3... Minibatch: 1... Step: 500... Loss: 15.923140... Val Loss: 17.116753\n",
      "Epoch: 3/3... Minibatch: 1... Step: 1000... Loss: 16.020920... Val Loss: 17.206656\n",
      "Epoch: 3/3... Minibatch: 1... Step: 1500... Loss: 21.830763... Val Loss: 17.069956\n",
      "Epoch: 3/3... Minibatch: 1... Step: 2000... Loss: 22.092880... Val Loss: 17.045448\n",
      "Epoch: 3/3... Minibatch: 1... Step: 2500... Loss: 13.561101... Val Loss: 17.046849\n",
      "Epoch: 3/3... Minibatch: 2... Step: 500... Loss: 7.619162... Val Loss: 17.225829\n",
      "Epoch: 3/3... Minibatch: 2... Step: 1000... Loss: 17.455208... Val Loss: 17.191674\n",
      "Epoch: 3/3... Minibatch: 2... Step: 1500... Loss: 14.996458... Val Loss: 17.206343\n",
      "Epoch: 3/3... Minibatch: 2... Step: 2000... Loss: 19.740822... Val Loss: 17.140978\n",
      "Epoch: 3/3... Minibatch: 2... Step: 2500... Loss: 17.314594... Val Loss: 17.151383\n",
      "Epoch: 3/3... Minibatch: 3... Step: 500... Loss: 18.717581... Val Loss: 17.382285\n",
      "Epoch: 3/3... Minibatch: 3... Step: 1000... Loss: 11.272805... Val Loss: 17.394649\n",
      "Epoch: 3/3... Minibatch: 3... Step: 1500... Loss: 13.010689... Val Loss: 17.388851\n",
      "Epoch: 3/3... Minibatch: 3... Step: 2000... Loss: 21.078869... Val Loss: 17.298641\n",
      "Epoch: 3/3... Minibatch: 3... Step: 2500... Loss: 13.967745... Val Loss: 17.331512\n",
      "Epoch: 3/3... Minibatch: 4... Step: 500... Loss: 19.352757... Val Loss: 17.001979\n",
      "Epoch: 3/3... Minibatch: 4... Step: 1000... Loss: 10.996716... Val Loss: 17.032183\n",
      "Epoch: 3/3... Minibatch: 4... Step: 1500... Loss: 14.135061... Val Loss: 16.992238\n",
      "Epoch: 3/3... Minibatch: 4... Step: 2000... Loss: 17.829903... Val Loss: 17.007767\n",
      "Epoch: 3/3... Minibatch: 4... Step: 2500... Loss: 12.618468... Val Loss: 16.967686\n",
      "Epoch: 3/3... Minibatch: 5... Step: 500... Loss: 17.301096... Val Loss: 16.715949\n",
      "Epoch: 3/3... Minibatch: 5... Step: 1000... Loss: 16.627312... Val Loss: 16.720220\n",
      "Epoch: 3/3... Minibatch: 5... Step: 1500... Loss: 14.215538... Val Loss: 16.770544\n",
      "Epoch: 3/3... Minibatch: 5... Step: 2000... Loss: 17.415560... Val Loss: 16.667239\n",
      "Epoch: 3/3... Minibatch: 5... Step: 2500... Loss: 21.620300... Val Loss: 16.626165\n",
      "Epoch: 3/3... Minibatch: 6... Step: 500... Loss: 16.611895... Val Loss: 16.982331\n",
      "Epoch: 3/3... Minibatch: 6... Step: 1000... Loss: 14.388529... Val Loss: 17.113984\n",
      "Epoch: 3/3... Minibatch: 6... Step: 1500... Loss: 17.096546... Val Loss: 16.991483\n",
      "Epoch: 3/3... Minibatch: 6... Step: 2000... Loss: 18.844053... Val Loss: 17.008825\n",
      "Epoch: 3/3... Minibatch: 6... Step: 2500... Loss: 17.497925... Val Loss: 17.095472\n",
      "Epoch: 3/3... Minibatch: 7... Step: 500... Loss: 19.375271... Val Loss: 16.932403\n",
      "Epoch: 3/3... Minibatch: 7... Step: 1000... Loss: 9.659400... Val Loss: 16.818087\n",
      "Epoch: 3/3... Minibatch: 7... Step: 1500... Loss: 13.921577... Val Loss: 17.005959\n",
      "Epoch: 3/3... Minibatch: 7... Step: 2000... Loss: 16.824390... Val Loss: 16.886475\n",
      "Epoch: 3/3... Minibatch: 7... Step: 2500... Loss: 17.284172... Val Loss: 16.892335\n",
      "Epoch: 3/3... Minibatch: 8... Step: 500... Loss: 9.926596... Val Loss: 17.005187\n",
      "Epoch: 3/3... Minibatch: 8... Step: 1000... Loss: 11.370829... Val Loss: 17.056181\n",
      "Epoch: 3/3... Minibatch: 8... Step: 1500... Loss: 11.167341... Val Loss: 17.002597\n",
      "Epoch: 3/3... Minibatch: 8... Step: 2000... Loss: 19.635107... Val Loss: 16.934357\n",
      "Epoch: 3/3... Minibatch: 8... Step: 2500... Loss: 12.428864... Val Loss: 16.904699\n",
      "Epoch: 3/3... Minibatch: 9... Step: 500... Loss: 14.192611... Val Loss: 17.019849\n",
      "Epoch: 3/3... Minibatch: 9... Step: 1000... Loss: 10.238380... Val Loss: 16.974573\n",
      "Epoch: 3/3... Minibatch: 9... Step: 1500... Loss: 14.870554... Val Loss: 17.037185\n",
      "Epoch: 3/3... Minibatch: 9... Step: 2000... Loss: 16.882473... Val Loss: 17.022658\n",
      "Epoch: 3/3... Minibatch: 9... Step: 2500... Loss: 16.258965... Val Loss: 17.071465\n"
     ]
    }
   ],
   "source": [
    "# largely adopted from in Udacity class example \"Sentiment_RNN\" workbook\n",
    "\"\"\"\n",
    "Train your model with dropout. Make sure to clip your gradients.\n",
    "Print the training loss, validation loss, and validation accuracy for every 100 steps.\n",
    "\"\"\"\n",
    "#training parameters\n",
    "epochs = 3\n",
    "minibatch = 10\n",
    "batch_size = 20\n",
    "clip =5\n",
    "print_every = 500\n",
    "\n",
    "# loss and optimization functions\n",
    "learning_rate = 0.0001\n",
    "criterion = nn.NLLLoss(size_average=False)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# move model to GPU, if available\n",
    "if (train_on_gpu):\n",
    "    model.cuda()\n",
    "\n",
    "# training mode\n",
    "model.train()\n",
    "\n",
    "# train over epochs\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}'.format(epoch + 1))\n",
    "    \n",
    "    for i in range(minibatch):\n",
    "        \n",
    "        # obtain one batch of training data\n",
    "        train_data, valid_data = format_data(i)\n",
    "\n",
    "        # dataloaders\n",
    "        batch_size = 20\n",
    "\n",
    "        # make sure the SHUFFLE your training data\n",
    "        train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "        valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "        \n",
    "        # initialize step counter\n",
    "        steps = i\n",
    "\n",
    "        # initialize hidden state\n",
    "        hidden = model.init_hidden(batch_size=labels.shape[0])\n",
    "\n",
    "        # batch loop\n",
    "        for features, labels in train_loader:\n",
    "\n",
    "            #transpose input to be (sequence_len, batch_size)\n",
    "            features = features.t()\n",
    "\n",
    "            # increment step counter\n",
    "            steps += 1\n",
    "\n",
    "            # Set Device\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            for each in hidden:\n",
    "                each.to(device)    \n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            hidden = tuple([each.data for each in hidden])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # get the output from the model\n",
    "            output, hidden = model(features, hidden)\n",
    "\n",
    "            # TODO Implement: Train Model\n",
    "            #output = output.unsqueeze(1)\n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss stats\n",
    "            if steps % print_every == 0:\n",
    "\n",
    "                # Get validation loss\n",
    "                val_h = model.init_hidden(batch_size=labels.shape[0])\n",
    "\n",
    "                # Set the device per reviewer recommendation\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "                for each in hidden:\n",
    "                    each.to(device)\n",
    "\n",
    "                val_losses = []\n",
    "                model.eval()\n",
    "                for features, labels in valid_loader:\n",
    "\n",
    "                    # transpose input to be (sequence_length, batch_size)\n",
    "                    features = features.t()\n",
    "\n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                    if(train_on_gpu):\n",
    "                        features, labels = features.cuda(), labels.cuda()\n",
    "\n",
    "                    output, val_h = model(features, val_h)\n",
    "                    val_loss = criterion(output, labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                model.train()\n",
    "                print(\"Epoch: {}/{}...\".format(epoch+1, epochs),\n",
    "                      \"Minibatch: {}...\".format(i),\n",
    "                      \"Step: {}...\".format(steps),\n",
    "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "\n",
    "        # save model indicating minibatch\n",
    "        torch.save(model.state_dict(), \"resume_weights_mb{}.pth\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model indicating minibatch\n",
    "torch.save(model.state_dict(), \"text_class_040819.pth\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['embedding.weight', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l1', 'lstm.weight_hh_l1', 'lstm.bias_ih_l1', 'lstm.bias_hh_l1', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = torch.load(\"text_class_040819.pth\", map_location=lambda storage, loc: storage)\n",
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "### Prediction \n",
    "Okay, now that you have a trained model, try it on some new twits and see if it works appropriately. Remember that for any new text, you'll need to preprocess it first before passing it to the network. Implement the `predict` function to generate the prediction vector from a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, vocab):\n",
    "    \"\"\" \n",
    "    Make a prediction on a single sentence.\n",
    "    Parameters\n",
    "    ----------\n",
    "        text : The string to make a prediction on.\n",
    "        model : The model to use for making the prediction.\n",
    "        vocab : Dictionary for word to word ids. The key is the word and the value is the word id.\n",
    "    Returns\n",
    "    -------\n",
    "        pred : Prediction vector\n",
    "    \"\"\"    \n",
    "    \n",
    "    # TODO Implement\n",
    "    # Clean sentance and tokenize\n",
    "    tokens = preprocess(text)\n",
    "    \n",
    "    # Filter non-vocab words\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    \n",
    "    # Convert words to ids\n",
    "    token_ids = [vocab[w] for w in tokens]\n",
    "    \n",
    "    # Test length of token_ids is > zero\n",
    "    \n",
    "    if len(token_ids) > 0:\n",
    "        \n",
    "        # Adding a batch dimension\n",
    "        text_input = torch.cuda.LongTensor([0]*(12-len(tokens)) + token_ids)\n",
    "        \n",
    "        # Init Hidden\n",
    "        hidden = model.init_hidden(1)\n",
    "        \n",
    "        # Get the model info\n",
    "        logps, _ = model(text_input.unsqueeze(1), hidden)\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        pred = torch.exp(logps)\n",
    "        \n",
    "    else:\n",
    "        # Indeterminant\n",
    "        pred = torch.cuda.LongTensor([0,0,0,0,0])\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (embedding): Embedding(20939, 400)\n",
       "  (lstm): LSTM(400, 256, num_layers=2, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (sig): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_class(val_tensor):\n",
    "    \"\"\" \n",
    "    Return Class predicted from validation_tensor.\n",
    "    Parameters\n",
    "    ----------\n",
    "    val_tensor : A input tensor from validation set.\n",
    "    -------\n",
    "    returns : Prediction Class: 0,1,2,3,4\n",
    "    \"\"\"\n",
    "    #convert numpy array to torch tensor\n",
    "    val_tens = torch.from_numpy(val_tensor).type(torch.cuda.LongTensor)\n",
    "    #make prediction and convert to class\n",
    "    hidden = model.init_hidden(1)\n",
    "    logps, _ = model(val_tens.unsqueeze(1), hidden)\n",
    "    pred = torch.exp(logps).mean(0)\n",
    "    values, indices = torch.max(torch.exp(pred),0)\n",
    "    return indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0140,  0.0453,  0.7193,  0.2118,  0.0096]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Google Tensor Flow is a hot potatoe, price may be meteoric $goog\"\n",
    "predict(text, model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0da5b959093404fb03a0c2448bff538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7476998119403280f60cafe0784146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a386f1ef033f41179fd4a3ac73158976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec19cad9d65842b180c551f228a36912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fdffcab9984386bfa3e5f57c19552d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88896493bc33413dbcd3563217cc5077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8b0f6200104374b8c66bb08bf36114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886bf689fd284c39a85419971b6310cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8660e442781841ae878f8ef29ee1233e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0128999a94645f6b6b078f737253cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "130000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the validation set classification performance\n",
    "y_pred=[]\n",
    "y_true=[]\n",
    "for i in range(10):\n",
    "    for j in tqdm_notebook(range(len(vx_list[i]))):\n",
    "        y_pred.append(pred_class(vx_list[i][j]))\n",
    "        y_true.append(vy_list[i][j])\n",
    "#check length is 130,000    \n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.73      0.76      0.75     25914\n",
      "    class 1       0.66      0.60      0.63     26012\n",
      "    class 2       0.62      0.74      0.67     25884\n",
      "    class 3       0.62      0.51      0.56     26246\n",
      "    class 4       0.73      0.76      0.75     25944\n",
      "\n",
      "avg / total       0.67      0.67      0.67    130000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1', 'class 2','class 3', 'class 4']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff84b86a1d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cmap = plt.get_cmap('Blues')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "plt.title(\"Text Classifier Validation Confusion\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0070,  0.0656,  0.0416,  0.6360,  0.2497]], device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Google is working on self driving cars, I'm bullish on $goog\"\n",
    "model.eval()\n",
    "#model.to(\"cpu\")\n",
    "predict(text, model, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: What is the prediction of the model? What is the uncertainty of the prediction?  \n",
    "> The prediction of the model for the Google Car text is Class 3. \n",
    "> This class has the highest probability over other classes at 0.4959.  \n",
    "> The classification metrics for class 3 is 0.62 precision, 0.51 recall, and 0.56 F1-score.  \n",
    ">\n",
    "> In this case, the probability of 0.63 confidence or certainty corresponds   \n",
    "> to 0.37 lack of certainty or uncertainty, where the two sum to one.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a trained model and we can make predictions. We can use this model to track the sentiments of various stocks by predicting the sentiments of twits as they are coming in. Now we have a stream of twits. For each of those twits, pull out the stocks mentioned in them and keep track of the sentiments. Remember that in the twits, ticker symbols are encoded with a dollar sign as the first character, all caps, and 2-4 letters, like $AAPL. Ideally, you'd want to track the sentiments of the stocks in your universe and use this as a signal in your larger model(s).\n",
    "\n",
    "## Testing\n",
    "### Load the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('..', '..', 'data', 'project_6_stocktwits', 'test_twits.json'), 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_twits.json', 'w') as outfile:\n",
    "    json.dump(test_data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twit Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_body': '$JWN has moved -1.69% on 10-31. Check out the movement and peers at  https://dividendbot.com?s=JWN',\n",
       " 'timestamp': '2018-11-01T00:00:05Z'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def twit_stream():\n",
    "    for twit in test_data['data']:\n",
    "        yield twit\n",
    "\n",
    "next(twit_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `prediction` function, let's apply it to a stream of twits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_twits(stream, model, vocab, universe):\n",
    "    \"\"\" \n",
    "    Given a stream of twits and a universe of tickers, return sentiment scores for tickers in the universe.\n",
    "    \"\"\"\n",
    "    for twit in stream:\n",
    "\n",
    "        # Get the message text\n",
    "        text = twit['message_body']\n",
    "        symbols = re.findall('\\$[A-Z]{2,4}', text)\n",
    "        score = predict(text, model, vocab)\n",
    "\n",
    "        for symbol in symbols:\n",
    "            if symbol in universe:\n",
    "                yield {'symbol': symbol, 'score': score, 'timestamp': twit['timestamp']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'symbol': '$AAPL',\n",
       " 'score': tensor([[ 0.1653,  0.0407,  0.2162,  0.1190,  0.4587]], device='cuda:0'),\n",
       " 'timestamp': '2018-11-01T00:00:18Z'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universe = {'$BBRY', '$AAPL', '$AMZN', '$BABA', '$YHOO', '$LQMT', '$FB', '$GOOG', '$BBBY', '$JNUG', '$SBUX', '$MU'}\n",
    "score_stream = score_twits(twit_stream(), model, vocab, universe)\n",
    "\n",
    "next(score_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. You have successfully built a functional model for sentiment analysis! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Now that you're done with the project, it's time to submit it. Click the submit button in the bottom right. One of our reviewers will give you feedback on your project with a pass or not passed grade. You can continue to the next section while you wait for feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
